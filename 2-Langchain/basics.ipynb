{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a46a4a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef12f91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "## Langsmith Tracking And Tracing\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c259db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentic AI refers to artificial intelligence (AI) systems that are capable of autonomous decision-making, problem-solving, and action-taking, often with a sense of purpose, intention, or goal-oriented behavior. The term \"agentic\" comes from the word \"agent,\" which in AI refers to a system that can perceive its environment, reason about it, and take actions to achieve its goals.\n",
      "\n",
      "Agentic AI systems are designed to be proactive, adaptive, and responsive to changing circumstances, rather than simply reacting to pre-programmed rules or instructions. They can learn from experience, make decisions based on uncertain or incomplete information, and adjust their behavior accordingly.\n",
      "\n",
      "Some key characteristics of agentic AI include:\n",
      "\n",
      "1. **Autonomy**: Agentic AI systems can operate independently, making decisions and taking actions without human intervention.\n",
      "2. **Goal-oriented behavior**: Agentic AI systems are designed to achieve specific goals or objectives, which can be defined by humans or learned through experience.\n",
      "3. **Reasoning and decision-making**: Agentic AI systems can reason about their environment, weigh options, and make decisions based on available information.\n",
      "4. **Learning and adaptation**: Agentic AI systems can learn from experience, adapt to changing circumstances, and improve their performance over time.\n",
      "5. **Proactivity**: Agentic AI systems can anticipate and respond to events, rather than simply reacting to them.\n",
      "\n",
      "Examples of agentic AI include:\n",
      "\n",
      "1. **Virtual assistants**: Virtual assistants like Siri, Alexa, or Google Assistant can understand voice commands, make decisions, and take actions to achieve specific goals (e.g., setting reminders, sending messages).\n",
      "2. **Autonomous vehicles**: Self-driving cars and drones can perceive their environment, make decisions, and take actions to navigate safely and efficiently.\n",
      "3. **Smart home systems**: Smart home systems can learn occupants' preferences, adjust lighting, temperature, and security settings, and optimize energy consumption.\n",
      "4. **Chatbots and conversational AI**: Chatbots can engage in natural-sounding conversations, understand context, and make decisions to provide helpful responses or take actions.\n",
      "\n",
      "Agentic AI has many potential benefits, including increased efficiency, improved decision-making, and enhanced customer experiences. However, it also raises important questions about accountability, transparency, and the potential risks and consequences of autonomous decision-making.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "response = model.invoke(\"what is Agentic AI?\").content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5adb8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an Ai Engineer, provide me the answer based on the question.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000019DE271EA50>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000019DE271F770>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", \"You are an Ai Engineer, provide me the answer based on the question.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | model\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cd4a204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangServe is an open-source language model serving system designed to simplify the deployment, management, and serving of large language models. It was developed by the team at Llama, a company that focuses on building AI models and tools.\n",
      "\n",
      "LangServe aims to provide a robust and scalable solution for serving language models, allowing developers to easily integrate these models into their applications. Here are some key features of LangServe:\n",
      "\n",
      "1. **Model Serving**: LangServe allows you to serve multiple language models simultaneously, making it easy to manage and switch between different models.\n",
      "2. **Scalability**: LangServe is designed to handle large volumes of requests, making it suitable for applications with high traffic.\n",
      "3. **Flexibility**: LangServe supports a wide range of language models, including popular models like BERT, RoBERTa, and XLNet.\n",
      "4. **Low-Latency**: LangServe is optimized for low-latency responses, ensuring that your application can respond quickly to user requests.\n",
      "5. **Multi-Model Support**: LangServe allows you to serve multiple models concurrently, enabling you to experiment with different models and choose the best one for your application.\n",
      "\n",
      "LangServe also provides a range of tools and APIs for managing and monitoring language models, including:\n",
      "\n",
      "1. **Model Management**: LangServe provides a simple API for uploading, updating, and deleting language models.\n",
      "2. **Model Monitoring**: LangServe provides real-time monitoring and logging capabilities, allowing you to track model performance and identify issues.\n",
      "3. **API Gateway**: LangServe includes an API gateway that provides a simple interface for interacting with language models.\n",
      "\n",
      "Overall, LangServe is a powerful tool for serving and managing language models, and it has the potential to simplify the process of integrating AI models into applications.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"input\": \"tell me something about langserve?\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1851f764",
   "metadata": {},
   "source": [
    "### Output parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f05aebe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangServe is an open-source, language-agnostic, and framework-agnostic API gateway for large language models (LLMs) and other AI/ML models. It provides a unified interface for deploying, managing, and serving machine learning models in a scalable and secure manner.\n",
      "\n",
      "Here are some key features and benefits of LangServe:\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "1. **Model Serving**: LangServe allows you to deploy and serve multiple machine learning models, including LLMs, computer vision models, and more.\n",
      "2. **API Gateway**: It provides a unified API interface for clients to interact with the models, abstracting away the underlying model implementation details.\n",
      "3. **Model Management**: LangServe offers features for model versioning, monitoring, and updating, making it easier to manage the lifecycle of machine learning models.\n",
      "4. **Scalability**: It is designed to scale horizontally, allowing you to handle large volumes of requests and traffic.\n",
      "5. **Security**: LangServe provides features for authentication, authorization, and encryption, ensuring that your models and data are secure.\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "1. **Simplified Model Deployment**: LangServe simplifies the process of deploying machine learning models, allowing you to focus on developing and improving your models.\n",
      "2. **Improved Model Management**: It provides a centralized platform for managing multiple models, making it easier to track performance, update models, and troubleshoot issues.\n",
      "3. **Enhanced Security**: LangServe's security features help protect your models and data from unauthorized access and malicious activities.\n",
      "4. **Increased Scalability**: Its scalable architecture allows you to handle large volumes of requests and traffic, making it suitable for large-scale AI/ML deployments.\n",
      "\n",
      "LangServe supports a wide range of machine learning frameworks, including TensorFlow, PyTorch, and Scikit-Learn, and can be used with various programming languages, such as Python, Java, and C++.\n",
      "\n",
      "Overall, LangServe is a powerful tool for deploying, managing, and serving machine learning models, and can help organizations streamline their AI/ML workflows and improve the efficiency of their model development and deployment processes.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain1 = prompt | model | output_parser\n",
    "\n",
    "response = chain1.invoke({\"input\": \"tell me something about langserve?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc419e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'Return a JSON object.'}, template='Answer the user query in \\n {format_instruction} \\n {query}')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "output_parser_json = JsonOutputParser()\n",
    "\n",
    "prompt_json = PromptTemplate(\n",
    "    template=\"Answer the user query in \\n {format_instruction} \\n {query}\",\n",
    "    input_variables = ['query'],\n",
    "    partial_variables = {\"format_instruction\": output_parser_json.get_format_instructions()}\n",
    ")\n",
    "\n",
    "prompt_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4553e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'LangServe', 'description': 'LangServe is a language server that provides a common interface for various programming languages, allowing for features like code completion, debugging, and diagnostics.', 'features': ['Code completion', 'Debugging', 'Diagnostics', 'Code refactoring', 'Code navigation'], 'benefits': ['Improved coding efficiency', 'Enhanced code quality', 'Better error detection and correction', 'Simplified code maintenance and refactoring'], 'supported_languages': ['C', 'C++', 'Java', 'Python', 'JavaScript', 'Ruby', 'Swift', 'Go', 'Rust'], 'supported_editors': ['Visual Studio Code', 'Sublime Text', 'Atom', 'Brackets', 'Emacs']}\n"
     ]
    }
   ],
   "source": [
    "chain_json = prompt_json | model | output_parser_json\n",
    "response = chain_json.invoke({\"query\": \"tell me something about langserve?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c0a01b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07604e30",
   "metadata": {},
   "source": [
    "### With Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b48f2ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"location\": {\"title\": \"Location\", \"type\": \"string\"}, \"temperature\": {\"title\": \"Temperature\", \"type\": \"number\"}, \"condition\": {\"title\": \"Condition\", \"type\": \"string\"}}, \"required\": [\"location\", \"temperature\", \"condition\"]}\\n```'}, template='Answer the user query in \\n {format_instruction} \\n {query}')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel,Field\n",
    "\n",
    "class WeatherResponse(BaseModel):\n",
    "    location: str\n",
    "    temperature: float\n",
    "    condition: str\n",
    "\n",
    "output_parser_pydantic = JsonOutputParser(pydantic_object=WeatherResponse)\n",
    "\n",
    "prompt_weather = PromptTemplate(\n",
    "    template=\"Answer the user query in \\n {format_instruction} \\n {query}\",\n",
    "    input_variables = ['query'],\n",
    "    partial_variables = {\"format_instruction\": output_parser_pydantic.get_format_instructions()}\n",
    ")\n",
    "\n",
    "prompt_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b5fa19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location': 'Chennai', 'temperature': 32.5, 'condition': 'Sunny'}\n"
     ]
    }
   ],
   "source": [
    "chain_weather = prompt_weather | model | output_parser_pydantic\n",
    "\n",
    "response = chain_weather.invoke({\"query\": \"what the weather in chennai today\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f453cca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
